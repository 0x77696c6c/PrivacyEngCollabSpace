# PixelDP

**Name of Tool:** PixelDP

**Primary Focus Area (select one):** De-identification

**De-identification Keywords:** Differential Privacy,
Verification of Algorithms, Machine Learning, Adversarial Examples

**Brief Description:** Adversarial examples that fool prediction models are a
new class of attacks introduced by machine learning
deployments. PixelDP is the first certified defense that both offers provable
guarantees of robustness against these attacks and
scales to large models and datasets, such as Googleâ€™s Inception on the ImageNet
dataset. PixelDP's design relies on a novel use of
differential privacy at prediction time.

**Additional Notes:** This [IEEE S&P 2019 research paper](https://csdl.computer.org/csdl/proceedings/sp/2019/6660/00/666000a727.pdf) describes
PixelDP.

**GitHub User Serving as POC (or Email Address):** @matlecu

**Affiliation/Organization(s) Contributing (if relevant):** Columbia University

 **Tool Link:** PixelDP's code can be found on [GitHub](https://github.com/columbia/pixeldp).
